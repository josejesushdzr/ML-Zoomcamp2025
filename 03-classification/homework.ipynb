{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d42a0b",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly.\n",
    "> That's fine.\n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "```\n",
    "\n",
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not.\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For categorical features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 \n",
    "\n",
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n",
    "\n",
    "- `NA`\n",
    "- `technology`\n",
    "- `healthcare`\n",
    "- `retail`\n",
    "\n",
    "ANSWER: `RETAIL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360efef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8233b88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bead1f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a25425",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7858ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          128\n",
       "industry             134\n",
       "employment_status    100\n",
       "location              63\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "208e93fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e060421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3919/2460796177.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[cat].replace(np.nan, 'NAN', inplace=True)\n",
      "/tmp/ipykernel_3919/2460796177.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[num].replace(np.nan, 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "categorical = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "for cat in categorical:\n",
    "    df[cat].replace(np.nan, 'NAN', inplace=True)\n",
    "\n",
    "for num in numerical:\n",
    "    df[num].replace(np.nan, 0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0e58979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0\n",
       "industry             0\n",
       "employment_status    0\n",
       "location             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ae840ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c7b4ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NAN              134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.industry.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa6d3e",
   "metadata": {},
   "source": [
    "\n",
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset.\n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- `interaction_count` and `lead_score`\n",
    "- `number_of_courses_viewed` and `lead_score`\n",
    "- `number_of_courses_viewed` and `interaction_count`\n",
    "- `annual_income` and `interaction_count`\n",
    "\n",
    "Only consider the pairs above when answering this question.\n",
    "\n",
    "### Split the data\n",
    "\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "- Make sure that the target value `converted` is not in your dataframe.\n",
    "\n",
    "### Question 3\n",
    "\n",
    "- Calculate the mutual information score between `converted` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "- `industry`\n",
    "- `location`\n",
    "- `lead_source`\n",
    "- `employment_status`\n",
    "\n",
    "### Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.64\n",
    "- 0.74\n",
    "- 0.84\n",
    "- 0.94\n",
    "\n",
    "### Question 5\n",
    "\n",
    "- Let's find the least useful feature using the _feature elimination_ technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `'industry'`\n",
    "- `'employment_status'`\n",
    "- `'lead_score'`\n",
    "\n",
    "> **Note**: The difference doesn't have to be positive.\n",
    "\n",
    "### Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `C`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
